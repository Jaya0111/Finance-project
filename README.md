We begin by installing the necessary dependencies, `feedparser` and `streamlit`, followed by importing essential libraries. Next, we fetch financial news from the requested URL using an API key, ensuring the request is successful (HTTP 200 OK). The JSON response is then parsed to extract article titles and descriptions. Additionally, we retrieve news from an RSS feed, extracting article titles and summaries. To prepare the text data, we clean it by removing URLs, punctuation, and converting it to lowercase for consistent processing. This allows for efficient preprocessing, where articles are converted into a Pandas DataFrame, cleaned, and assigned dummy sentiment labels (1 = positive, 0 = negative). We then train a sentiment model by loading the preprocessed data from a CSV file, splitting it into training (80%) and testing (20%) sets, converting text into TF-IDF features to assess word importance, and training a Naive Bayes classifier to detect sentiment before saving the trained model and vectorizer using `joblib`. Moving forward, we implement an interactive web app using Streamlit, which displays "Financial Sentiment Analysis" on a web page, fetches live news when a button is clicked, and presents articles with their sentiment labels in a structured table. For Named Entity Recognition (NER), we utilize an NLP model to identify companies, people, and financial terms, extracting relevant entities from news headlines. Finally, we execute the full pipeline, fetching both RSS and API news, saving the data to a CSV file, and training the sentiment model on the updated dataset.

I have also tried to work on the optional step. But I was having issues with the flask appliaction. I tried to open the Flask app and it was showing me error. I tried multiple times changing some steps but It didn't work.
